{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '../data/malcolm_clean_w_duration.csv'\n",
    "SAVE_DIR = '../data/'\n",
    "DURATIONS = [21, 25, 27, 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 1663\n",
      "number of unique mids: 1663\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA)\n",
    "print('number of rows: ' + str(len(df)))\n",
    "print('number of unique mids: ' + str(df.MID.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, min_duration, fn):\n",
    "    d = df.loc[df.duration >= min_duration]\n",
    "    print('min_duration = ' + str(min_duration))\n",
    "    print('num rows: ' + str(len(d)))\n",
    "    d = d[['Study', 'Group', 'Drug', 'Control', 'MID', 'start_size', 'end_size', 'duration']]\n",
    "    d = d.rename(columns={'start_size': 'V0', 'end_size': 'V'})\n",
    "    # Compute V/V0, centered\n",
    "    old_len = len(d)\n",
    "    d['V/V0'] = d['V']/d['V0']\n",
    "    d = d.merge(d.groupby(['Study', 'Drug'])['V/V0'].mean().reset_index(name='V/V0_sm'),\n",
    "                on=['Study', 'Drug'],\n",
    "                validate='many_to_one')\n",
    "    d['V/V0_cen'] = d['V/V0'] - d['V/V0_sm']\n",
    "    assert (len(d) == old_len)\n",
    "    # Compute C0 for each Study-Drug pair\n",
    "    c = d.loc[d.Control == 1]\n",
    "    # each study has exactly one control\n",
    "    assert(c.groupby('Study').Drug.nunique().max() == 1)\n",
    "    assert(c.groupby('Study').Drug.nunique().min() == 1)\n",
    "    assert(c.groupby('Study').Group.nunique().max() == 1)\n",
    "    assert(c.groupby('Study').Group.nunique().min() == 1)\n",
    "    assert((c.Control == 1).all())\n",
    "    # Get C0 for each (Study, Drug) pair\n",
    "    old_mids = d.MID.nunique()\n",
    "    c = c[['Study', 'Group', 'Control', 'MID', 'V0']]\n",
    "    c_studies = c.Study.unique()\n",
    "    nmids_wo_control = d.loc[d.Study.isin(c_studies) == False].MID.nunique()\n",
    "    d = d.merge(c.groupby('Study')['V0'].mean().reset_index(name='C0'),\n",
    "                on=['Study'], \n",
    "                validate='many_to_one')\n",
    "    print('dropped ' + str(nmids_wo_control) + ' MIDs without a control with duration >= ' + str(min_duration))\n",
    "    assert(old_mids - d.MID.nunique() == nmids_wo_control)\n",
    "    # Compute V/C0, centered\n",
    "    old_len = len(d)\n",
    "    d['V/C0'] = d['V'] / d['C0']\n",
    "    d = d.merge(d.groupby(['Study', 'Drug'])['V/C0'].mean().reset_index(name='V/C0_sm'),\n",
    "                on=['Study', 'Drug'],\n",
    "                validate='many_to_one')\n",
    "    d['V/C0_cen'] = d['V/C0'] - d['V/C0_sm']\n",
    "    assert(len(d) == old_len)\n",
    "    # Compute log(V/C0), centered\n",
    "    old_len = len(d)\n",
    "    d['lg_V/C0'] = np.log(d['V/C0'])\n",
    "    d = d.merge(d.groupby(['Study', 'Drug'])['lg_V/C0'].mean().reset_index(name='lg_V/C0_sm'))\n",
    "    d['lg_V/C0_cen'] = d['lg_V/C0'] - d['lg_V/C0_sm']\n",
    "    print('num rows: ' + str(len(d)))\n",
    "    assert(len(d) == old_len)\n",
    "    d.to_csv(fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_duration = 21\n",
      "num rows: 1445\n",
      "dropped 75 MIDs without a control with duration >= 21\n",
      "num rows: 1370\n",
      "min_duration = 25\n",
      "num rows: 1159\n",
      "dropped 59 MIDs without a control with duration >= 25\n",
      "num rows: 1100\n",
      "min_duration = 27\n",
      "num rows: 911\n",
      "dropped 59 MIDs without a control with duration >= 27\n",
      "num rows: 852\n",
      "min_duration = 28\n",
      "num rows: 817\n",
      "dropped 52 MIDs without a control with duration >= 28\n",
      "num rows: 765\n"
     ]
    }
   ],
   "source": [
    "# process data for each duration\n",
    "for min_duration in DURATIONS:\n",
    "    fn = SAVE_DIR + 'min_duration_' + str(min_duration) + '.csv'\n",
    "    process_data(df, min_duration, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1445"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.duration >= 21].MID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
