{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a2cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203872e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a simple model\n",
    "def model(obs=None, n_obs=None):\n",
    "    if n_obs == None:\n",
    "        n_obs = obs.shape[0]\n",
    "    mu = pyro.sample('mu', dist.Normal(torch.zeros(()), torch.ones(())))\n",
    "    mean = mu * torch.ones(n_obs,)\n",
    "    sigma = torch.ones(n_obs,)\n",
    "    with pyro.plate('data_plate', n_obs):\n",
    "        data = pyro.sample('data', dist.Normal(mean, sigma), obs=obs)\n",
    "    return mu, data\n",
    "\n",
    "def predict(mcmc_samples, n_obs):\n",
    "    mu = np.array(mcmc_samples['mu'])\n",
    "    assert mu.shape[0] == n_obs\n",
    "    return mu\n",
    "\n",
    "def r_squared(mu, test):\n",
    "    mean = np.mean(mu, axis=0)\n",
    "    pearson_corr = np.corrcoef(test, mean * np.ones(len(test),))\n",
    "    r = pearson_corr[0, 1]\n",
    "    return np.power(r, 2)\n",
    "\n",
    "# function to compute coverage\n",
    "def coverage(mu, obs, hi, lo):\n",
    "    assert hi > lo\n",
    "    # generate synthetic samples from normal distribution with mean mu\n",
    "    m = mu.shape[0]\n",
    "    # generate synthetic samples for each observation\n",
    "    # TODO: Figure out how to get correct variance in here\n",
    "    synth = mu + np.random.normal(loc=0, scale=1, size=(m,))\n",
    "    # sort synthetic samples for each observation\n",
    "    sorted_synth = np.sort(synth, axis=0)\n",
    "    # compute hi and lo index\n",
    "    lo_idx = int(np.ceil(lo * m))\n",
    "    hi_idx = int(np.floor(hi * m))\n",
    "    # get synthetic samples at hi and lo indices\n",
    "    lo_bound = sorted_synth[lo_idx]\n",
    "    hi_bound = sorted_synth[hi_idx]\n",
    "    # is obs in [hi, lo]?\n",
    "    frac = np.sum(np.logical_and(lo_bound < obs, obs < hi_bound) / (1.0 * len(obs)))\n",
    "    return frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af57bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the model: train, test\n",
    "true_mu, obs = model(n_obs=1000)\n",
    "obs_train = obs[0:800]\n",
    "obs_test = obs[800:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7247ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4049)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59a2f497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|                                           | 0/50500 [00:00, ?it/s]/Users/michelameister/opt/anaconda3/lib/python3.8/site-packages/pyro/poutine/subsample_messenger.py:63: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  result = torch.tensor(0.0, device=self.device)\n",
      "Sample: 100%|â–ˆ| 50500/50500 [00:52, 953.00it/s, step size=1.14e+00, acc. prob=0.\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "pyro.clear_param_store()\n",
    "kernel = pyro.infer.mcmc.NUTS(model, jit_compile=True)\n",
    "mcmc = pyro.infer.MCMC(kernel, num_samples=50000, warmup_steps=500)\n",
    "mcmc.run(obs=obs_train)\n",
    "mcmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}\n",
    "# to start, just compute mu and compare with true_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e95ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 50000\n",
    "mu = predict(mcmc_samples, n_obs)\n",
    "#r_sq = r_squared(mu, obs_test)\n",
    "frac = coverage(mu, obs_test, .95, .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('frac: ' + str(frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6805f241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frac: 0.9199999999999999\n"
     ]
    }
   ],
   "source": [
    "first_mcmc = {'mu': mcmc_samples['mu'][:500]}\n",
    "mu = predict(first_mcmc, 500)\n",
    "#r_sq = r_squared(mu, obs_test)\n",
    "frac = coverage(mu, obs_test, .95, .05)\n",
    "print('frac: ' + str(frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23079ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(mu, axis=0)\n",
    "pearson_corr = np.corrcoef(obs_test, mean * np.ones(len(obs_test),))\n",
    "r = pearson_corr[0, 1]\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(mu, axis=0)\n",
    "print(mean)\n",
    "pearson_corr = np.corrcoef(obs_test, mean * np.ones(len(obs_test),))\n",
    "print(pearson_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b67345",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([1, 2, 3])\n",
    "arr2 = np.array([4, 5, 6])\n",
    "np.corrcoef(arr1, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84993302",
   "metadata": {},
   "outputs": [],
   "source": [
    "barr1 = 2 * np.array(np.ones(3,))\n",
    "barr2 = np.array(np.ones(3,))\n",
    "np.corrcoef(arr1, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "barr1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c37791",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r_sq: ' + str(r_sq))\n",
    "print('frac: ' + str(frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array(mcmc_samples['mu'])\n",
    "mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76aca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mu, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e059a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(mu, axis=0)\n",
    "np.ones(50000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbb33c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
