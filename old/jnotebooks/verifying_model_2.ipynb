{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6369efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyro\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "\n",
    "NUM_ARGS = 5\n",
    "A_SIGMA_INIT = 5\n",
    "G_ALPHA_INIT = 10\n",
    "G_BETA_INIT = 2\n",
    "ALPHA_INIT = 2\n",
    "BETA_INIT = 1\n",
    "\n",
    "# evaluate model\n",
    "N_SYNTH = 200\n",
    "LO = .05\n",
    "HI = .95\n",
    "NBINS = 20\n",
    "NUM_ARGS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6fb5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(fn):\n",
    "    with open(fn, 'rb') as handle:\n",
    "        obj = pickle.load(handle)\n",
    "    return obj\n",
    "\n",
    "def get_model_inputs(train_fn, sample_fn, drug_fn):\n",
    "    df = pd.read_pickle(train_fn)\n",
    "    sample_dict = read_pickle(sample_fn)\n",
    "    drug_dict = read_pickle(drug_fn)\n",
    "    n_samp = len(sample_dict.keys())\n",
    "    n_drug = len(drug_dict.keys())\n",
    "    s_idx = df['s_idx'].to_numpy()\n",
    "    d_idx = df['d_idx'].to_numpy()\n",
    "    obs = torch.Tensor(df['log(V_V0)'])\n",
    "    return n_samp, n_drug, s_idx, d_idx, obs\n",
    "\n",
    "def model(n_samp, n_drug, s_idx, d_idx, obs=None, n_obs=None):\n",
    "    if n_obs is None:\n",
    "        print('Error: n_obs is none!')\n",
    "    # create global offset\n",
    "    a_sigma = pyro.param('a_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
    "    a = pyro.sample('a', dist.Normal(torch.zeros(()), a_sigma * torch.ones(())))   \n",
    "    # create s\n",
    "    s_g_alpha = pyro.param('s_g_alpha', torch.Tensor([G_ALPHA_INIT]), constraint=constraints.positive)\n",
    "    s_g_beta = pyro.param('s_g_beta', torch.Tensor([G_BETA_INIT]), constraint=constraints.positive)\n",
    "    s_sigma = pyro.param('s_sigma', dist.Gamma(s_g_alpha, s_g_beta), constraint=constraints.positive)\n",
    "    a_s_sigma = pyro.param('a_s_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
    "    with pyro.plate('s_plate', n_samp):\n",
    "        a_s = pyro.sample('a_s', dist.Normal(torch.zeros(n_samp), a_s_sigma * torch.ones(n_samp)))\n",
    "        s = pyro.sample('s', dist.Normal(torch.zeros(n_samp), s_sigma * torch.ones(n_samp)))\n",
    "    # create d\n",
    "    d_g_alpha = pyro.param('d_g_alpha', torch.Tensor([G_ALPHA_INIT]), constraint=constraints.positive)\n",
    "    d_g_beta = pyro.param('d_g_beta', torch.Tensor([G_BETA_INIT]), constraint=constraints.positive)\n",
    "    d_sigma = pyro.param('d_sigma', dist.Gamma(d_g_alpha, d_g_beta), constraint=constraints.positive)\n",
    "    a_d_sigma = pyro.param('a_d_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
    "    with pyro.plate('d_plate', n_drug):\n",
    "        a_d = pyro.sample('a_d', dist.Normal(torch.zeros(n_drug), a_d_sigma * torch.ones(n_drug)))\n",
    "        d = pyro.sample('d', dist.Normal(torch.zeros(n_drug), d_sigma))\n",
    "    # create data\n",
    "    mean = s[s_idx] * d[d_idx] + a_s[s_idx] + a_d[d_idx] + a\n",
    "    sigma_g_alpha = pyro.param('sigma_g_alpha', torch.Tensor([ALPHA_INIT]), constraint=constraints.positive)\n",
    "    sigma_g_beta = pyro.param('sigma_g_beta', torch.Tensor([BETA_INIT]), constraint=constraints.positive)\n",
    "    sigma = pyro.sample('sigma', dist.Gamma(sigma_g_alpha, sigma_g_beta))\n",
    "    with pyro.plate('data_plate', n_obs):\n",
    "        data = pyro.sample('data', dist.Normal(mean, sigma * torch.ones(n_obs)), obs=obs)\n",
    "    return data\n",
    "\n",
    "def predict(mcmc_samples, s_test_idx, d_test_idx):\n",
    "    assert len(s_test_idx) == len(d_test_idx)\n",
    "    n = len(s_test_idx)\n",
    "    # read in mcmc samples for each variable\n",
    "    s = np.array(mcmc_samples['s']) \n",
    "    d = np.array(mcmc_samples['d'])\n",
    "    a = np.array(mcmc_samples['a'])\n",
    "    a_s = np.array(mcmc_samples['a_s'])\n",
    "    a_d = np.array(mcmc_samples['a_d'])\n",
    "    sigma = np.array(mcmc_samples['sigma'])\n",
    "    # combine above matrices to create mu\n",
    "    m = s.shape[0]\n",
    "    mu = np.multiply(s[0:m, s_test_idx], d[0:m, d_test_idx]) + a_s[0:m, s_test_idx] + a_d[0:m, d_test_idx] + a\n",
    "    assert (mu.shape[0] == m) and (mu.shape[1] == n)\n",
    "    assert (sigma.shape[0] == m) and (sigma.shape[1] == 1)\n",
    "    return mu, sigma\n",
    "\n",
    "def r_squared(mu, test):\n",
    "    means = np.mean(mu, axis=0)\n",
    "    assert means.shape[0] == test.shape[0]\n",
    "    pearson_corr = np.corrcoef(test, means)\n",
    "    r = pearson_corr[0, 1]\n",
    "    return np.power(r, 2)\n",
    "\n",
    "# function to compute coverage\n",
    "def coverage(mu, sigma, obs, hi, lo):\n",
    "    # generate synthetic samples from normal distribution with mean mu\n",
    "    m = mu.shape[0]\n",
    "    n = mu.shape[1]\n",
    "    # generate synthetic samples for each observation\n",
    "    # TODO: Figure out how to get correct variance in here\n",
    "    synth = mu + sigma * np.random.normal(loc=0, scale=1, size=(m, n))\n",
    "    # sort synthetic samples for each observation\n",
    "    sorted_synth = np.sort(synth, axis=0)\n",
    "    # compute hi and lo index\n",
    "    lo_idx = int(np.ceil(lo * m))\n",
    "    hi_idx = int(np.floor(hi * m))\n",
    "    # get synthetic samples at hi and lo indices\n",
    "    lo_bound = sorted_synth[lo_idx, :]\n",
    "    hi_bound = sorted_synth[hi_idx, :]\n",
    "    # is obs in [hi, lo]?\n",
    "    frac = np.sum(np.logical_and(lo_bound < obs, obs < hi_bound) / (1.0 * len(obs)))\n",
    "    return frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97728471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thinning_idx(n_total, n_desired):\n",
    "    idx = np.linspace(0, n_total, num=n_desired)\n",
    "    assert (np.floor(idx) == np.ceil(idx)).all()\n",
    "    return np.array(idx, dtype=int)\n",
    "\n",
    "# thin mcmc_samples\n",
    "def thinning(mcmc_samples, keys, n_total, n_desired):\n",
    "    indices = get_thinning_idx(n_total, n_desired+1)\n",
    "    thinned_samples = {}\n",
    "    for key in keys:\n",
    "        thinned_samples[key] = mcmc_samples[key][indices[:-1]]\n",
    "    return thinned_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "665fd46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in model inputs\n",
    "base_dir = '../results/2023-06-09/clean_and_split_data/split'\n",
    "train_fn = base_dir + '/train.pkl'\n",
    "test_fn = base_dir + '/test.pkl'\n",
    "sample_fn = base_dir + '/sample_dict.pkl'\n",
    "drug_fn = base_dir + '/drug_dict.pkl'\n",
    "\n",
    "n_samp, n_drug, s_idx, d_idx, _ = get_model_inputs(train_fn, sample_fn, drug_fn)\n",
    "_, _, s_test_idx, d_test_idx, _ = get_model_inputs(test_fn, sample_fn, drug_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd490090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data\n",
    "n_train = len(s_idx)\n",
    "n_test = len(s_test_idx)\n",
    "n_obs = n_train + n_test\n",
    "s_indices = np.concatenate((s_idx, s_test_idx))\n",
    "d_indices = np.concatenate((d_idx, d_test_idx))\n",
    "obs = model(n_samp, n_drug, s_indices, d_indices, n_obs=n_obs)\n",
    "obs_train = obs[0:n_train]\n",
    "obs_test = obs[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ea0d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|                                            | 0/1000 [00:00, ?it/s]/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2542154387.py:21: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  a_sigma = pyro.param('a_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2542154387.py:24: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  s_g_alpha = pyro.param('s_g_alpha', torch.Tensor([G_ALPHA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2542154387.py:25: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  s_g_beta = pyro.param('s_g_beta', torch.Tensor([G_BETA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2542154387.py:27: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  a_s_sigma = pyro.param('a_s_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2542154387.py:32: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  d_g_alpha = pyro.param('d_g_alpha', torch.Tensor([G_ALPHA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2542154387.py:33: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  d_g_beta = pyro.param('d_g_beta', torch.Tensor([G_BETA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2542154387.py:35: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  a_d_sigma = pyro.param('a_d_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2542154387.py:41: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  sigma_g_alpha = pyro.param('sigma_g_alpha', torch.Tensor([ALPHA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2542154387.py:42: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  sigma_g_beta = pyro.param('sigma_g_beta', torch.Tensor([BETA_INIT]), constraint=constraints.positive)\n",
      "/Users/michelameister/opt/anaconda3/lib/python3.8/site-packages/pyro/poutine/subsample_messenger.py:63: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  result = torch.tensor(0.0, device=self.device)\n",
      "Sample: 100%|█| 1000/1000 [02:31,  6.59it/s, step size=5.97e-02, acc. prob=0.876\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "pyro.clear_param_store()\n",
    "kernel = pyro.infer.mcmc.NUTS(model, jit_compile=True)\n",
    "mcmc = pyro.infer.MCMC(kernel, num_samples=500, warmup_steps=500)\n",
    "mcmc.run(n_samp, n_drug, s_idx, d_idx, obs=obs_train, n_obs=n_train)\n",
    "mcmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = obs_test.numpy()\n",
    "# write samples to file\n",
    "with open('../mcmc_samples.pkl', 'wb') as handle:\n",
    "    pickle.dump(mcmc_samples, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c302ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = predict(mcmc_samples, s_test_idx, d_test_idx)\n",
    "r_sq = r_squared(mu, test)\n",
    "fracs = coverage(mu, sigma, test, HI, LO)\n",
    "print(\"fracs: \" + str(fracs))\n",
    "print(\"r_sq: \" + str(r_sq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
