{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6369efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyro\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "\n",
    "NUM_ARGS = 5\n",
    "A_SIGMA_INIT = 5\n",
    "G_ALPHA_INIT = 10\n",
    "G_BETA_INIT = 2\n",
    "ALPHA_INIT = 2\n",
    "BETA_INIT = 1\n",
    "\n",
    "# evaluate model\n",
    "N_SYNTH = 200\n",
    "LO = .05\n",
    "HI = .95\n",
    "NBINS = 20\n",
    "NUM_ARGS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6fb5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(fn):\n",
    "    with open(fn, 'rb') as handle:\n",
    "        obj = pickle.load(handle)\n",
    "    return obj\n",
    "\n",
    "def get_model_inputs(train_fn, sample_fn, drug_fn):\n",
    "    df = pd.read_pickle(train_fn)\n",
    "    sample_dict = read_pickle(sample_fn)\n",
    "    drug_dict = read_pickle(drug_fn)\n",
    "    n_samp = len(sample_dict.keys())\n",
    "    n_drug = len(drug_dict.keys())\n",
    "    s_idx = df['s_idx'].to_numpy()\n",
    "    d_idx = df['d_idx'].to_numpy()\n",
    "    obs = torch.Tensor(df['log(V_V0)'])\n",
    "    return n_samp, n_drug, s_idx, d_idx, obs\n",
    "\n",
    "def model(n_samp, n_drug, s_idx, d_idx, obs):\n",
    "    # create global offset\n",
    "    a_sigma = pyro.param('a_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
    "    a = pyro.sample('a', dist.Normal(torch.zeros(()), a_sigma * torch.ones(())))   \n",
    "    # create s\n",
    "    s_g_alpha = pyro.param('s_g_alpha', torch.Tensor([G_ALPHA_INIT]), constraint=constraints.positive)\n",
    "    s_g_beta = pyro.param('s_g_beta', torch.Tensor([G_BETA_INIT]), constraint=constraints.positive)\n",
    "    s_sigma = pyro.param('s_sigma', dist.Gamma(s_g_alpha, s_g_beta), constraint=constraints.positive)\n",
    "    a_s_sigma = pyro.param('a_s_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
    "    with pyro.plate('s_plate', n_samp):\n",
    "        a_s = pyro.sample('a_s', dist.Normal(torch.zeros(n_samp), a_s_sigma * torch.ones(n_samp)))\n",
    "        s = pyro.sample('s', dist.Normal(torch.zeros(n_samp), s_sigma * torch.ones(n_samp)))\n",
    "    # create d\n",
    "    d_g_alpha = pyro.param('d_g_alpha', torch.Tensor([G_ALPHA_INIT]), constraint=constraints.positive)\n",
    "    d_g_beta = pyro.param('d_g_beta', torch.Tensor([G_BETA_INIT]), constraint=constraints.positive)\n",
    "    d_sigma = pyro.param('d_sigma', dist.Gamma(d_g_alpha, d_g_beta), constraint=constraints.positive)\n",
    "    a_d_sigma = pyro.param('a_d_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
    "    with pyro.plate('d_plate', n_drug):\n",
    "        a_d = pyro.sample('a_d', dist.Normal(torch.zeros(n_drug), a_d_sigma * torch.ones(n_drug)))\n",
    "        d = pyro.sample('d', dist.Normal(torch.zeros(n_drug), d_sigma))\n",
    "    # create data\n",
    "    mean = s[s_idx] * d[d_idx] + a_s[s_idx] + a_d[d_idx] + a\n",
    "    sigma_g_alpha = pyro.param('sigma_g_alpha', torch.Tensor([ALPHA_INIT]), constraint=constraints.positive)\n",
    "    sigma_g_beta = pyro.param('sigma_g_beta', torch.Tensor([BETA_INIT]), constraint=constraints.positive)\n",
    "    sigma = pyro.sample('sigma', dist.Gamma(sigma_g_alpha, sigma_g_beta))\n",
    "    with pyro.plate('data_plate', obs.shape[0]):\n",
    "        pyro.sample('data', dist.Normal(mean, sigma * torch.ones(obs.shape[0])), obs=obs)\n",
    "        \n",
    "def small_model(n_samp, n_drug, s_idx, d_idx, obs):\n",
    "    with pyro.plate('s_plate', n_samp):\n",
    "        s = pyro.sample('s', dist.Normal(torch.zeros(n_samp), torch.ones(n_samp)))\n",
    "    mean = s[s_idx]\n",
    "    with pyro.plate('data_plate', obs.shape[0]):\n",
    "        pyro.sample('data', dist.Normal(mean, torch.ones(obs.shape[0])), obs=obs)\n",
    "        \n",
    "def generate_synthetic_samples(n_samp, n_drug, s_idx, d_idx):\n",
    "    n_synth = len(s_idx)\n",
    "    # # create global offset\n",
    "    a = np.random.normal(loc=0, scale=A_SIGMA_INIT)  \n",
    "    # create s\n",
    "    s_sigma = np.random.gamma(5)\n",
    "    a_s = np.random.normal(0, A_SIGMA_INIT, size=(n_samp,))\n",
    "    s = np.random.normal(0, s_sigma, size=(n_samp,))\n",
    "    # create d\n",
    "    d_sigma = np.random.gamma(5)\n",
    "    a_d = np.random.normal(0, A_SIGMA_INIT, size=(n_drug,))\n",
    "    d = np.random.normal(0, d_sigma, size=(n_drug,))\n",
    "    # create data\n",
    "    mean = s[s_idx] * d[d_idx] + a_s[s_idx] + a_d[d_idx] + a\n",
    "    sigma = np.random.gamma(5)\n",
    "    data = mean + sigma * np.random.normal(loc=0, scale=1, size=(n_synth,))\n",
    "    return torch.Tensor(data)\n",
    "\n",
    "def small_synth(n_samp, n_drug, s_idx, d_idx):\n",
    "    s = np.random.normal(0, 1, size=(n_samp,))\n",
    "    data = s[s_idx]\n",
    "    return torch.Tensor(data)\n",
    "\n",
    "def predict(mcmc_samples, s_test_idx, d_test_idx):\n",
    "    assert len(s_test_idx) == len(d_test_idx)\n",
    "    n = len(s_test_idx)\n",
    "    # read in mcmc samples for each variable\n",
    "    s = np.array(mcmc_samples['s']) \n",
    "    d = np.array(mcmc_samples['d'])\n",
    "    a = np.array(mcmc_samples['a'])\n",
    "    a_s = np.array(mcmc_samples['a_s'])\n",
    "    a_d = np.array(mcmc_samples['a_d'])\n",
    "    sigma = np.array(mcmc_samples['sigma'])\n",
    "    # combine above matrices to create mu\n",
    "    m = s.shape[0]\n",
    "    mu = np.multiply(s[0:m, s_test_idx], d[0:m, d_test_idx]) + a_s[0:m, s_test_idx] + a_d[0:m, d_test_idx] + a\n",
    "    assert (mu.shape[0] == m) and (mu.shape[1] == n)\n",
    "    assert (sigma.shape[0] == m) and (sigma.shape[1] == 1)\n",
    "    return mu, sigma\n",
    "\n",
    "def small_predict(mcmc_samples, s_test_idx, d_test_idx):\n",
    "    assert len(s_test_idx) == len(d_test_idx)\n",
    "    n = len(s_test_idx)\n",
    "    # read in mcmc samples for each variable\n",
    "    s = np.array(mcmc_samples['s']) \n",
    "    # combine above matrices to create mu\n",
    "    m = s.shape[0]\n",
    "    mu = s[0:m, s_test_idx]\n",
    "    assert (mu.shape[0] == m) and (mu.shape[1] == n)\n",
    "    return mu, 1\n",
    "\n",
    "def r_squared(mu, test):\n",
    "    means = np.mean(mu, axis=0)\n",
    "    assert means.shape[0] == test.shape[0]\n",
    "    pearson_corr = np.corrcoef(test, means)\n",
    "    r = pearson_corr[0, 1]\n",
    "    return np.power(r, 2)\n",
    "\n",
    "# function to compute coverage\n",
    "def coverage(mu, sigma, obs, hi, lo):\n",
    "    # generate synthetic samples from normal distribution with mean mu\n",
    "    m = mu.shape[0]\n",
    "    n = mu.shape[1]\n",
    "    # generate synthetic samples for each observation\n",
    "    # TODO: Figure out how to get correct variance in here\n",
    "    synth = mu + sigma * np.random.normal(loc=0, scale=1, size=(m, n))\n",
    "    # sort synthetic samples for each observation\n",
    "    sorted_synth = np.sort(synth, axis=0)\n",
    "    # compute hi and lo index\n",
    "    lo_idx = int(np.ceil(lo * m))\n",
    "    hi_idx = int(np.floor(hi * m))\n",
    "    # get synthetic samples at hi and lo indices\n",
    "    lo_bound = sorted_synth[lo_idx, :]\n",
    "    hi_bound = sorted_synth[hi_idx, :]\n",
    "    # is obs in [hi, lo]?\n",
    "    frac = np.sum(np.logical_and(lo_bound < obs, obs < hi_bound) / (1.0 * len(obs)))\n",
    "    return frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97728471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thinning_idx(n_total, n_desired):\n",
    "    idx = np.linspace(0, n_total, num=n_desired)\n",
    "    assert (np.floor(idx) == np.ceil(idx)).all()\n",
    "    return np.array(idx, dtype=int)\n",
    "\n",
    "# thin mcmc_samples\n",
    "def thinning(mcmc_samples, keys, n_total, n_desired):\n",
    "    indices = get_thinning_idx(n_total, n_desired+1)\n",
    "    thinned_samples = {}\n",
    "    for key in keys:\n",
    "        thinned_samples[key] = mcmc_samples[key][indices[:-1]]\n",
    "    return thinned_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "665fd46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in model inputs\n",
    "base_dir = '../results/2023-06-09/clean_and_split_data/split'\n",
    "train_fn = base_dir + '/train.pkl'\n",
    "test_fn = base_dir + '/test.pkl'\n",
    "sample_fn = base_dir + '/sample_dict.pkl'\n",
    "drug_fn = base_dir + '/drug_dict.pkl'\n",
    "\n",
    "n_samp, n_drug, s_idx, d_idx, _ = get_model_inputs(train_fn, sample_fn, drug_fn)\n",
    "_, _, s_test_idx, d_test_idx, _ = get_model_inputs(test_fn, sample_fn, drug_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "069cf241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|                                           | 0/50500 [00:00, ?it/s]/Users/michelameister/opt/anaconda3/lib/python3.8/site-packages/pyro/poutine/subsample_messenger.py:63: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  result = torch.tensor(0.0, device=self.device)\n",
      "Sample: 100%|â–ˆ| 50500/50500 [02:25, 347.28it/s, step size=6.21e-01, acc. prob=0.\n"
     ]
    }
   ],
   "source": [
    "# SMALL MODEL\n",
    "obs_train = small_synth(n_samp, n_drug, s_idx, d_idx)\n",
    "obs_test = small_synth(n_samp, n_drug, s_test_idx, d_test_idx)\n",
    "\n",
    "# fit model\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.8.4')\n",
    "pyro.enable_validation(True)\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "\n",
    "# Set matplotlib settings\n",
    "plt.style.use('default')\n",
    "\n",
    "n_samp, n_drug, s_idx, d_idx, obs = get_model_inputs(train_fn, sample_fn, drug_fn)\n",
    "pyro.render_model(small_model, model_args=(n_samp, n_drug, s_idx, d_idx, obs_train), render_params=True, \n",
    "                  render_distributions=True)\n",
    "pyro.clear_param_store()\n",
    "kernel = pyro.infer.mcmc.NUTS(small_model, jit_compile=True)\n",
    "mcmc = pyro.infer.MCMC(kernel, num_samples=50000, warmup_steps=500)\n",
    "mcmc.run(n_samp, n_drug, s_idx, d_idx, obs_train)\n",
    "mcmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e06d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = obs_test.numpy()\n",
    "# write samples to file\n",
    "with open('../mcmc_samples.pkl', 'wb') as handle:\n",
    "    pickle.dump(mcmc_samples, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e2f28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mcmc_samples['s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30c8299d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fracs: 0.6081081081081081\n",
      "r_sq: 0.4394464938252599\n"
     ]
    }
   ],
   "source": [
    "# try on all samples\n",
    "mu, sigma = small_predict(mcmc_samples, s_test_idx, d_test_idx)\n",
    "r_sq = r_squared(mu, test)\n",
    "fracs = coverage(mu, sigma, test, HI, LO)\n",
    "print(\"fracs: \" + str(fracs))\n",
    "print(\"r_sq: \" + str(r_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a7d81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5758101 , 1.5758101 , 1.5758101 , ..., 0.8813013 , 0.8813013 ,\n",
       "        0.8813013 ],\n",
       "       [1.7985806 , 1.7985806 , 1.7985806 , ..., 0.75204885, 0.75204885,\n",
       "        0.75204885],\n",
       "       [1.8482765 , 1.8482765 , 1.8482765 , ..., 2.0345535 , 2.0345535 ,\n",
       "        2.0345535 ],\n",
       "       ...,\n",
       "       [1.47381   , 1.47381   , 1.47381   , ..., 1.6391413 , 1.6391413 ,\n",
       "        1.6391413 ],\n",
       "       [1.9076245 , 1.9076245 , 1.9076245 , ..., 1.0366187 , 1.0366187 ,\n",
       "        1.0366187 ],\n",
       "       [1.4720681 , 1.4720681 , 1.4720681 , ..., 1.6586899 , 1.6586899 ,\n",
       "        1.6586899 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85f9f580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fracs: 0.6351351351351352\n",
      "r_sq: 0.4474179130058454\n"
     ]
    }
   ],
   "source": [
    "# try on thinned samples\n",
    "thinned_samples = thinning(mcmc_samples, ['s'], 50000, 500)\n",
    "mu, sigma = small_predict(thinned_samples, s_test_idx, d_test_idx)\n",
    "r_sq = r_squared(mu, test)\n",
    "fracs = coverage(mu, sigma, test, HI, LO)\n",
    "print(\"fracs: \" + str(fracs))\n",
    "print(\"r_sq: \" + str(r_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09159c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try on first 500 samples\n",
    "thinned_samples = thinning(mcmc_samples, ['s'], 50000, 500)\n",
    "mu, sigma = small_predict(thinned_samples, s_test_idx, d_test_idx)\n",
    "r_sq = r_squared(mu, test)\n",
    "fracs = coverage(mu, sigma, test, HI, LO)\n",
    "print(\"fracs: \" + str(fracs))\n",
    "print(\"r_sq: \" + str(r_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b7d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = np.array(np.linspace(0, 50000, num=501), dtype=int)[0:499]\n",
    "thinned_samples = thinning(mcmc_samples, ['s'], 50000, 500)\n",
    "mu, sigma = small_predict(thinned_samples, s_test_idx, d_test_idx)\n",
    "r_sq = r_squared(mu, test)\n",
    "fracs = coverage(mu, sigma, test, HI, LO)\n",
    "print(\"fracs: \" + str(fracs))\n",
    "print(\"r_sq: \" + str(r_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb0aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_thin_idx = np.array(range(0, 500))\n",
    "no_thin_samples = thinning(mcmc_samples, 's', no_thin_idx)\n",
    "test = obs_test.numpy()\n",
    "mu, sigma = small_predict(no_thin_samples, s_test_idx, d_test_idx)\n",
    "r_sq = r_squared(mu, test)\n",
    "fracs = coverage(mu, sigma, test, HI, LO)\n",
    "print(\"fracs: \" + str(fracs))\n",
    "print(\"r_sq: \" + str(r_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aec5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD/OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc58b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMAL MODEL\n",
    "obs_train = generate_synthetic_samples(n_samp, n_drug, s_idx, d_idx)\n",
    "obs_test = generate_synthetic_samples(n_samp, n_drug, s_test_idx, d_test_idx)\n",
    "\n",
    "# fit model\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.8.4')\n",
    "pyro.enable_validation(True)\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "\n",
    "# Set matplotlib settings\n",
    "plt.style.use('default')\n",
    "\n",
    "n_samp, n_drug, s_idx, d_idx, obs = get_model_inputs(train_fn, sample_fn, drug_fn)\n",
    "pyro.render_model(model, model_args=(n_samp, n_drug, s_idx, d_idx, obs_train), render_params=True, \n",
    "                  render_distributions=True)\n",
    "pyro.clear_param_store()\n",
    "kernel = pyro.infer.mcmc.NUTS(model, jit_compile=True)\n",
    "mcmc = pyro.infer.MCMC(kernel, num_samples=500, warmup_steps=500)\n",
    "mcmc.run(n_samp, n_drug, s_idx, d_idx, obs)\n",
    "mcmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
