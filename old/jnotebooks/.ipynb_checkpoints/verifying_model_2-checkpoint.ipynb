{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6369efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyro\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "\n",
    "NUM_ARGS = 5\n",
    "A_SIGMA_INIT = 5\n",
    "G_ALPHA_INIT = 10\n",
    "G_BETA_INIT = 2\n",
    "ALPHA_INIT = 2\n",
    "BETA_INIT = 1\n",
    "\n",
    "# evaluate model\n",
    "N_SYNTH = 200\n",
    "LO = .05\n",
    "HI = .95\n",
    "NBINS = 20\n",
    "NUM_ARGS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6fb5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(fn):\n",
    "    with open(fn, 'rb') as handle:\n",
    "        obj = pickle.load(handle)\n",
    "    return obj\n",
    "\n",
    "def get_model_inputs(train_fn, sample_fn, drug_fn):\n",
    "    df = pd.read_pickle(train_fn)\n",
    "    sample_dict = read_pickle(sample_fn)\n",
    "    drug_dict = read_pickle(drug_fn)\n",
    "    n_samp = len(sample_dict.keys())\n",
    "    n_drug = len(drug_dict.keys())\n",
    "    s_idx = df['s_idx'].to_numpy()\n",
    "    d_idx = df['d_idx'].to_numpy()\n",
    "    obs = torch.Tensor(df['log(V_V0)'])\n",
    "    return n_samp, n_drug, s_idx, d_idx, obs\n",
    "\n",
    "def model(n_samp, n_drug, s_idx, d_idx, obs=None, n_obs=None):\n",
    "    if n_obs is None:\n",
    "        print('Error: n_obs is none!')\n",
    "    # create global offset\n",
    "    a_sigma = pyro.param('a_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
    "    a = pyro.sample('a', dist.Normal(torch.zeros(()), a_sigma * torch.ones(())))   \n",
    "    # create s\n",
    "    s_g_alpha = pyro.param('s_g_alpha', torch.Tensor([G_ALPHA_INIT]), constraint=constraints.positive)\n",
    "    s_g_beta = pyro.param('s_g_beta', torch.Tensor([G_BETA_INIT]), constraint=constraints.positive)\n",
    "    s_sigma = pyro.param('s_sigma', dist.Gamma(s_g_alpha, s_g_beta), constraint=constraints.positive)\n",
    "    a_s_sigma = pyro.param('a_s_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
    "    with pyro.plate('s_plate', n_samp):\n",
    "        a_s = pyro.sample('a_s', dist.Normal(torch.zeros(n_samp), a_s_sigma * torch.ones(n_samp)))\n",
    "        s = pyro.sample('s', dist.Normal(torch.zeros(n_samp), s_sigma * torch.ones(n_samp)))\n",
    "    # create d\n",
    "    d_g_alpha = pyro.param('d_g_alpha', torch.Tensor([G_ALPHA_INIT]), constraint=constraints.positive)\n",
    "    d_g_beta = pyro.param('d_g_beta', torch.Tensor([G_BETA_INIT]), constraint=constraints.positive)\n",
    "    d_sigma = pyro.param('d_sigma', dist.Gamma(d_g_alpha, d_g_beta), constraint=constraints.positive)\n",
    "    a_d_sigma = pyro.param('a_d_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
    "    with pyro.plate('d_plate', n_drug):\n",
    "        a_d = pyro.sample('a_d', dist.Normal(torch.zeros(n_drug), a_d_sigma * torch.ones(n_drug)))\n",
    "        d = pyro.sample('d', dist.Normal(torch.zeros(n_drug), d_sigma))\n",
    "    # create data\n",
    "    mean = s[s_idx] * d[d_idx] + a_s[s_idx] + a_d[d_idx] + a\n",
    "    sigma_g_alpha = pyro.param('sigma_g_alpha', torch.Tensor([ALPHA_INIT]), constraint=constraints.positive)\n",
    "    sigma_g_beta = pyro.param('sigma_g_beta', torch.Tensor([BETA_INIT]), constraint=constraints.positive)\n",
    "    sigma = pyro.sample('sigma', dist.Gamma(sigma_g_alpha, sigma_g_beta))\n",
    "    with pyro.plate('data_plate', n_obs):\n",
    "        data = pyro.sample('data', dist.Normal(mean, sigma * torch.ones(n_obs)), obs=obs)\n",
    "    return data\n",
    "\n",
    "def predict(mcmc_samples, s_test_idx, d_test_idx):\n",
    "    assert len(s_test_idx) == len(d_test_idx)\n",
    "    n = len(s_test_idx)\n",
    "    # read in mcmc samples for each variable\n",
    "    s = np.array(mcmc_samples['s']) \n",
    "    d = np.array(mcmc_samples['d'])\n",
    "    a = np.array(mcmc_samples['a'])\n",
    "    a_s = np.array(mcmc_samples['a_s'])\n",
    "    a_d = np.array(mcmc_samples['a_d'])\n",
    "    sigma = np.array(mcmc_samples['sigma'])\n",
    "    # combine above matrices to create mu\n",
    "    m = s.shape[0]\n",
    "    mu = np.multiply(s[0:m, s_test_idx], d[0:m, d_test_idx]) + a_s[0:m, s_test_idx] + a_d[0:m, d_test_idx] + a\n",
    "    assert (mu.shape[0] == m) and (mu.shape[1] == n)\n",
    "    assert (sigma.shape[0] == m) and (sigma.shape[1] == 1)\n",
    "    return mu, sigma\n",
    "\n",
    "def r_squared(mu, test):\n",
    "    means = np.mean(mu, axis=0)\n",
    "    assert means.shape[0] == test.shape[0]\n",
    "    pearson_corr = np.corrcoef(test, means)\n",
    "    r = pearson_corr[0, 1]\n",
    "    return np.power(r, 2)\n",
    "\n",
    "# function to compute coverage\n",
    "def coverage(mu, sigma, obs, hi, lo):\n",
    "    # generate synthetic samples from normal distribution with mean mu\n",
    "    m = mu.shape[0]\n",
    "    n = mu.shape[1]\n",
    "    # generate synthetic samples for each observation\n",
    "    # TODO: Figure out how to get correct variance in here\n",
    "    synth = mu + sigma * np.random.normal(loc=0, scale=1, size=(m, n))\n",
    "    # sort synthetic samples for each observation\n",
    "    sorted_synth = np.sort(synth, axis=0)\n",
    "    # compute hi and lo index\n",
    "    lo_idx = int(np.ceil(lo * m))\n",
    "    hi_idx = int(np.floor(hi * m))\n",
    "    # get synthetic samples at hi and lo indices\n",
    "    lo_bound = sorted_synth[lo_idx, :]\n",
    "    hi_bound = sorted_synth[hi_idx, :]\n",
    "    # is obs in [hi, lo]?\n",
    "    frac = np.sum(np.logical_and(lo_bound < obs, obs < hi_bound) / (1.0 * len(obs)))\n",
    "    return frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97728471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thinning_idx(n_total, n_desired):\n",
    "    idx = np.linspace(0, n_total, num=n_desired)\n",
    "    assert (np.floor(idx) == np.ceil(idx)).all()\n",
    "    return np.array(idx, dtype=int)\n",
    "\n",
    "# thin mcmc_samples\n",
    "def thinning(mcmc_samples, keys, n_total, n_desired):\n",
    "    indices = get_thinning_idx(n_total, n_desired+1)\n",
    "    thinned_samples = {}\n",
    "    for key in keys:\n",
    "        thinned_samples[key] = mcmc_samples[key][indices[:-1]]\n",
    "    return thinned_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "665fd46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in model inputs\n",
    "base_dir = '../results/2023-06-09/clean_and_split_data/split'\n",
    "train_fn = base_dir + '/train.pkl'\n",
    "test_fn = base_dir + '/test.pkl'\n",
    "sample_fn = base_dir + '/sample_dict.pkl'\n",
    "drug_fn = base_dir + '/drug_dict.pkl'\n",
    "\n",
    "n_samp, n_drug, s_idx, d_idx, _ = get_model_inputs(train_fn, sample_fn, drug_fn)\n",
    "_, _, s_test_idx, d_test_idx, _ = get_model_inputs(test_fn, sample_fn, drug_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd490090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data\n",
    "n_train = len(s_idx)\n",
    "n_test = len(s_test_idx)\n",
    "n_obs = n_train + n_test\n",
    "s_indices = np.concatenate((s_idx, s_test_idx))\n",
    "d_indices = np.concatenate((d_idx, d_test_idx))\n",
    "obs = model(n_samp, n_drug, s_indices, d_indices, n_obs=n_obs)\n",
    "obs_train = obs[0:n_train]\n",
    "obs_test = obs[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ea0d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|                                            | 0/1000 [00:00, ?it/s]/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2913209030.py:23: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  a_sigma = pyro.param('a_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2913209030.py:26: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  s_g_alpha = pyro.param('s_g_alpha', torch.Tensor([G_ALPHA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2913209030.py:27: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  s_g_beta = pyro.param('s_g_beta', torch.Tensor([G_BETA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2913209030.py:29: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  a_s_sigma = pyro.param('a_s_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2913209030.py:34: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  d_g_alpha = pyro.param('d_g_alpha', torch.Tensor([G_ALPHA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2913209030.py:35: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  d_g_beta = pyro.param('d_g_beta', torch.Tensor([G_BETA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2913209030.py:37: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  a_d_sigma = pyro.param('a_d_sigma', torch.Tensor([A_SIGMA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2913209030.py:43: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  sigma_g_alpha = pyro.param('sigma_g_alpha', torch.Tensor([ALPHA_INIT]), constraint=constraints.positive)\n",
      "/var/folders/qp/_x0hhd1j55x6rc8v_jztj07c0000gn/T/ipykernel_77312/2913209030.py:44: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  sigma_g_beta = pyro.param('sigma_g_beta', torch.Tensor([BETA_INIT]), constraint=constraints.positive)\n",
      "/Users/michelameister/opt/anaconda3/lib/python3.8/site-packages/pyro/poutine/subsample_messenger.py:63: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  result = torch.tensor(0.0, device=self.device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot insert a Tensor that requires grad as a constant. Consider making it a parameter or input, or detaching the gradient\nTensor:\n-15.7785\n-17.3181\n-16.8563\n-15.6248\n-17.4221\n  4.6188\n  5.8440\n  3.4789\n  4.6240\n-32.2047\n-30.2448\n-32.2395\n-31.5930\n-32.3500\n  0.8709\n  1.1038\n  1.4503\n-12.4038\n -8.8347\n-10.2517\n-10.5156\n-10.0270\n  5.7666\n  7.1093\n  7.2268\n  6.8779\n  5.7103\n  5.2769\n -6.7331\n -8.9344\n -7.0700\n  3.1327\n  3.7667\n  1.8467\n  3.0167\n-31.3603\n-29.6720\n-28.2264\n  2.3190\n  3.3913\n  4.6814\n  2.6532\n  4.4836\n-10.4213\n-10.3907\n-12.5592\n -7.3531\n -6.6523\n -7.2563\n -7.1749\n -7.9741\n -6.7637\n -5.9409\n -7.8353\n -6.5018\n -5.6325\n -7.2194\n -6.0557\n -7.1518\n  2.9835\n  3.0892\n  2.3411\n -2.3627\n -4.3967\n -2.8578\n -3.3362\n -2.9456\n -3.2100\n -1.5777\n -1.9455\n  0.1370\n -0.6577\n -0.7096\n  0.5481\n  0.2912\n -0.4591\n -6.2676\n -7.5440\n -6.0813\n -5.1336\n -6.5303\n  1.2923\n  2.1156\n  1.6752\n  1.3264\n  1.2682\n -3.1730\n -3.0475\n -1.1250\n-10.0694\n-10.2799\n-10.7305\n-10.6575\n-10.5533\n-10.2211\n -8.6949\n-10.4910\n -8.9488\n-20.9080\n-19.8151\n-20.3233\n -8.8136\n -8.3711\n-10.3032\n -9.1251\n -8.4699\n -8.7583\n -9.6161\n -9.1810\n -9.6189\n -8.3306\n -9.1397\n -8.3181\n -8.2831\n -9.2427\n -8.1303\n-14.3813\n-12.3968\n-14.2328\n -5.3787\n -4.3032\n -3.9971\n -4.1904\n -3.8611\n -6.5986\n -5.9780\n -4.5597\n -4.0012\n -4.2477\n -4.8831\n -4.0760\n -4.6807\n -4.1568\n -5.1613\n -3.3751\n -3.2750\n -4.5424\n -4.1126\n -9.0589\n -6.3673\n -9.2105\n-12.8428\n-13.0934\n-14.6988\n-10.5391\n -9.8760\n-10.6942\n  7.3679\n  8.3905\n -2.4335\n -1.1391\n -1.6787\n -0.5574\n -6.5628\n -5.9858\n -5.6461\n -6.1484\n -5.2106\n -4.4242\n -5.1080\n -4.4824\n -4.1699\n -5.3628\n -6.9796\n-22.5189\n-22.9882\n-23.0432\n-23.8084\n-21.8643\n-17.2678\n-18.2682\n-17.9083\n-15.2474\n-15.6757\n-14.3401\n-15.0530\n-14.3906\n-13.6639\n-14.4055\n-13.0368\n-13.4645\n-12.8720\n -2.2804\n -2.6429\n -2.2021\n -1.8228\n -2.7003\n -1.3801\n  0.4816\n -2.5926\n[ torch.FloatTensor{190} ]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m kernel \u001b[38;5;241m=\u001b[39m pyro\u001b[38;5;241m.\u001b[39minfer\u001b[38;5;241m.\u001b[39mmcmc\u001b[38;5;241m.\u001b[39mNUTS(model, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m mcmc \u001b[38;5;241m=\u001b[39m pyro\u001b[38;5;241m.\u001b[39minfer\u001b[38;5;241m.\u001b[39mMCMC(kernel, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmcmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_drug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m mcmc_samples \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m mcmc\u001b[38;5;241m.\u001b[39mget_samples()\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_context_wrap\u001b[39m(context, fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyro/infer/mcmc/api.py:563\u001b[0m, in \u001b[0;36mMCMC.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m optional(\n\u001b[1;32m    555\u001b[0m     pyro\u001b[38;5;241m.\u001b[39mvalidation_enabled(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_validation),\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_validation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;66;03m# This also resolves \"RuntimeError: Cowardly refusing to serialize non-leaf tensor which\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;66;03m# requires_grad\", which happens with `jit_compile` under PyTorch 1.7\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m [arg\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(arg) \u001b[38;5;28;01melse\u001b[39;00m arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, chain_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m num_samples[chain_id] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    565\u001b[0m             num_samples[chain_id] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyro/infer/mcmc/api.py:223\u001b[0m, in \u001b[0;36m_UnarySampler.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m logger \u001b[38;5;241m=\u001b[39m initialize_logger(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, progress_bar)\n\u001b[1;32m    222\u001b[0m hook_w_logging \u001b[38;5;241m=\u001b[39m _add_logging_hook(logger, progress_bar, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook)\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m _gen_samples(\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel,\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_steps,\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples,\n\u001b[1;32m    227\u001b[0m     hook_w_logging,\n\u001b[1;32m    228\u001b[0m     i \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_chains \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    231\u001b[0m ):\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m sample, i  \u001b[38;5;66;03m# sample, chain_id\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyro/infer/mcmc/api.py:144\u001b[0m, in \u001b[0;36m_gen_samples\u001b[0;34m(kernel, warmup_steps, num_samples, hook, chain_id, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gen_samples\u001b[39m(kernel, warmup_steps, num_samples, hook, chain_id, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 144\u001b[0m     \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     params \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39minitial_params\n\u001b[1;32m    146\u001b[0m     save_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(kernel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_params\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28msorted\u001b[39m(params))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyro/infer/mcmc/hmc.py:348\u001b[0m, in \u001b[0;36mHMC.setup\u001b[0;34m(self, warmup_steps, *args, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_params:\n\u001b[1;32m    347\u001b[0m     z \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_params\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 348\u001b[0m     z_grads, potential_energy \u001b[38;5;241m=\u001b[39m \u001b[43mpotential_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpotential_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     z_grads, potential_energy \u001b[38;5;241m=\u001b[39m {}, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpotential_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_params)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyro/ops/integrator.py:90\u001b[0m, in \u001b[0;36mpotential_grad\u001b[0;34m(potential_fn, z)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m grads, z_nodes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnew_tensor(\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     91\u001b[0m grads \u001b[38;5;241m=\u001b[39m grad(potential_energy, z_nodes)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m z_nodes:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyro/ops/integrator.py:83\u001b[0m, in \u001b[0;36mpotential_grad\u001b[0;34m(potential_fn, z)\u001b[0m\n\u001b[1;32m     81\u001b[0m     node\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     potential_energy \u001b[38;5;241m=\u001b[39m \u001b[43mpotential_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# handle exceptions as defined in the exception registry\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyro/infer/mcmc/util.py:309\u001b[0m, in \u001b[0;36m_PEMaker._potential_fn_jit\u001b[0;34m(self, skip_jit_warnings, jit_options, params)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip_jit_warnings:\n\u001b[1;32m    308\u001b[0m     _pe_jit \u001b[38;5;241m=\u001b[39m ignore_jit_warnings()(_pe_jit)\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_pe_jit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mjit_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_fn(\u001b[38;5;241m*\u001b[39mvals)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m tmp:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/jit/_trace.py:795\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support compiling individual module\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms functions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use trace_module\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m     )\n\u001b[1;32m    794\u001b[0m name \u001b[38;5;241m=\u001b[39m _qualified_name(func)\n\u001b[0;32m--> 795\u001b[0m traced \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_function_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_callable_argument_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_trace:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyro/infer/mcmc/util.py:305\u001b[0m, in \u001b[0;36m_PEMaker._potential_fn_jit.<locals>._pe_jit\u001b[0;34m(*zi)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pe_jit\u001b[39m(\u001b[38;5;241m*\u001b[39mzi):\n\u001b[1;32m    304\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(names, zi))\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_potential_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyro/infer/mcmc/util.py:281\u001b[0m, in \u001b[0;36m_PEMaker._potential_fn\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    277\u001b[0m cond_model \u001b[38;5;241m=\u001b[39m poutine\u001b[38;5;241m.\u001b[39mcondition(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, params_constrained)\n\u001b[1;32m    278\u001b[0m model_trace \u001b[38;5;241m=\u001b[39m poutine\u001b[38;5;241m.\u001b[39mtrace(cond_model)\u001b[38;5;241m.\u001b[39mget_trace(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[1;32m    280\u001b[0m )\n\u001b[0;32m--> 281\u001b[0m log_joint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_prob_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    283\u001b[0m     log_joint \u001b[38;5;241m=\u001b[39m log_joint \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\n\u001b[1;32m    284\u001b[0m         t\u001b[38;5;241m.\u001b[39mlog_abs_det_jacobian(params_constrained[name], params[name])\n\u001b[1;32m    285\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyro/infer/mcmc/util.py:238\u001b[0m, in \u001b[0;36mTraceEinsumEvaluator.log_prob\u001b[0;34m(self, model_trace)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03mReturns the log pdf of `model_trace` by appropriately handling\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03menumerated log prob factors.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m:return: log pdf of the trace.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_enumerable_sites:\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_trace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_log_factors(model_trace)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shared_intermediates() \u001b[38;5;28;01mas\u001b[39;00m cache:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyro/poutine/trace_struct.py:196\u001b[0m, in \u001b[0;36mTrace.log_prob_sum\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         log_p \u001b[38;5;241m=\u001b[39m \u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m            \u001b[49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    200\u001b[0m         _, exc_value, traceback \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/distributions/normal.py:81\u001b[0m, in \u001b[0;36mNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     79\u001b[0m var \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     80\u001b[0m log_scale \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale, Real) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\u001b[38;5;241m.\u001b[39mlog()\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m((\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m var) \u001b[38;5;241m-\u001b[39m log_scale \u001b[38;5;241m-\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot insert a Tensor that requires grad as a constant. Consider making it a parameter or input, or detaching the gradient\nTensor:\n-15.7785\n-17.3181\n-16.8563\n-15.6248\n-17.4221\n  4.6188\n  5.8440\n  3.4789\n  4.6240\n-32.2047\n-30.2448\n-32.2395\n-31.5930\n-32.3500\n  0.8709\n  1.1038\n  1.4503\n-12.4038\n -8.8347\n-10.2517\n-10.5156\n-10.0270\n  5.7666\n  7.1093\n  7.2268\n  6.8779\n  5.7103\n  5.2769\n -6.7331\n -8.9344\n -7.0700\n  3.1327\n  3.7667\n  1.8467\n  3.0167\n-31.3603\n-29.6720\n-28.2264\n  2.3190\n  3.3913\n  4.6814\n  2.6532\n  4.4836\n-10.4213\n-10.3907\n-12.5592\n -7.3531\n -6.6523\n -7.2563\n -7.1749\n -7.9741\n -6.7637\n -5.9409\n -7.8353\n -6.5018\n -5.6325\n -7.2194\n -6.0557\n -7.1518\n  2.9835\n  3.0892\n  2.3411\n -2.3627\n -4.3967\n -2.8578\n -3.3362\n -2.9456\n -3.2100\n -1.5777\n -1.9455\n  0.1370\n -0.6577\n -0.7096\n  0.5481\n  0.2912\n -0.4591\n -6.2676\n -7.5440\n -6.0813\n -5.1336\n -6.5303\n  1.2923\n  2.1156\n  1.6752\n  1.3264\n  1.2682\n -3.1730\n -3.0475\n -1.1250\n-10.0694\n-10.2799\n-10.7305\n-10.6575\n-10.5533\n-10.2211\n -8.6949\n-10.4910\n -8.9488\n-20.9080\n-19.8151\n-20.3233\n -8.8136\n -8.3711\n-10.3032\n -9.1251\n -8.4699\n -8.7583\n -9.6161\n -9.1810\n -9.6189\n -8.3306\n -9.1397\n -8.3181\n -8.2831\n -9.2427\n -8.1303\n-14.3813\n-12.3968\n-14.2328\n -5.3787\n -4.3032\n -3.9971\n -4.1904\n -3.8611\n -6.5986\n -5.9780\n -4.5597\n -4.0012\n -4.2477\n -4.8831\n -4.0760\n -4.6807\n -4.1568\n -5.1613\n -3.3751\n -3.2750\n -4.5424\n -4.1126\n -9.0589\n -6.3673\n -9.2105\n-12.8428\n-13.0934\n-14.6988\n-10.5391\n -9.8760\n-10.6942\n  7.3679\n  8.3905\n -2.4335\n -1.1391\n -1.6787\n -0.5574\n -6.5628\n -5.9858\n -5.6461\n -6.1484\n -5.2106\n -4.4242\n -5.1080\n -4.4824\n -4.1699\n -5.3628\n -6.9796\n-22.5189\n-22.9882\n-23.0432\n-23.8084\n-21.8643\n-17.2678\n-18.2682\n-17.9083\n-15.2474\n-15.6757\n-14.3401\n-15.0530\n-14.3906\n-13.6639\n-14.4055\n-13.0368\n-13.4645\n-12.8720\n -2.2804\n -2.6429\n -2.2021\n -1.8228\n -2.7003\n -1.3801\n  0.4816\n -2.5926\n[ torch.FloatTensor{190} ]"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "pyro.clear_param_store()\n",
    "kernel = pyro.infer.mcmc.NUTS(model, jit_compile=True)\n",
    "mcmc = pyro.infer.MCMC(kernel, num_samples=500, warmup_steps=500)\n",
    "mcmc.run(n_samp, n_drug, s_idx, d_idx, obs=obs_train, n_obs=n_train)\n",
    "mcmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = obs_test.numpy()\n",
    "# write samples to file\n",
    "with open('../mcmc_samples.pkl', 'wb') as handle:\n",
    "    pickle.dump(mcmc_samples, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c302ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = predict(mcmc_samples, s_test_idx, d_test_idx)\n",
    "r_sq = r_squared(mu, test)\n",
    "fracs = coverage(mu, sigma, test, HI, LO)\n",
    "print(\"fracs: \" + str(fracs))\n",
    "print(\"r_sq: \" + str(r_sq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
