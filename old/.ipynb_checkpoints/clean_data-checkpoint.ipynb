{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 5955\n"
     ]
    }
   ],
   "source": [
    "# edit DATA to load in welm_pdx.csv\n",
    "DATA = '../welm/data/welm_pdx.csv'\n",
    "df = pd.read_csv(DATA)\n",
    "print('Number of rows: ' + str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Navitoclax', 'Vehicle', 'Docetaxel', 'E2 pellet only',\n",
       "       'E2 pellet + E2 water', 'E2', 'OVX', 'Intact', 'Birinapant',\n",
       "       'RO4929097', 'Irinotecan', 'Birinapant + Irinotecan',\n",
       "       'Fulvestrant (40 mg/kg)', 'Fulvestrant (200 mg/kg)', 'Fulvestrant',\n",
       "       'AC-T', 'Eribulin', 'Enzalutamide', 'Cabozantinib', 'Talazoparib'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collapse drug names\n",
    "df['Drug'] = df['Drug'].str.strip()\n",
    "df['Drug'] = df['Drug'].replace('vehicle', 'Vehicle')\n",
    "df.Drug.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove data from the following figures...\n",
    "# Extended Data Fig 1: This data is from testing the response of tumor samples to estrogen.\n",
    "# 3h: This data is an experiment involving retreatment related to drug resistance.\n",
    "# '7d mid right', vehicle lines only: Data duplicated in Figure 6\n",
    "# 7e, vehicle & birinapant lines: These are repeated in 7c\n",
    "# 8: No drug overlap with in-vitro drugs. And Fig 8 is related to real-time tests for a single patient.\n",
    "# So Fig 8 is somewhat different from other figs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all data from Extended Data Fig 1\n",
    "extended_data_fig1_fn = '43018_2022_337_MOESM11_ESM.xlsx'\n",
    "df = df.loc[df['source_file'] != extended_data_fig1_fn]\n",
    "\n",
    "# Remove all data from Fig 8\n",
    "fig8_fn = '43018_2022_337_MOESM10_ESM.xlsx'\n",
    "df = df.loc[df['source_file'] != fig8_fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove data from 3h left and 3h right\n",
    "df = df.loc[~df['excel_sheet'].isin(['3h left', '3h right'])]\n",
    "\n",
    "# Remove data from 6d sheets, vehicle lines only\n",
    "sheet_6d = ['6d left', '6d mid left', '6d mid', '6d mid right']\n",
    "df = df.loc[~((df['excel_sheet'].isin(sheet_6d)) & (df['Drug'] == 'Vehicle'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove data from sheet '7d mid right', vehicle lines only\n",
    "df = df.loc[~((df['excel_sheet'] == '7d mid right') & (df['Drug'] == 'Vehicle'))]\n",
    "\n",
    "# Remove data from 7e, vehicle and birinapant lines only\n",
    "sheet_7e = ['7e left', '7e mid', '7e right']\n",
    "df = df.loc[~((df['excel_sheet'].isin(sheet_7e)) & (df['Drug'].isin(['Birinapant', 'Vehicle'])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Sample', 'Drug', 'Replicate Number', 'Day', 'Tumor Volume mm3']\n",
    "assert df.groupby(cols)['source_file'].nunique().max() == 1\n",
    "assert df.groupby(cols)['excel_sheet'].nunique().max() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2660\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows: ' + str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "df.to_csv('data/welm_pdx_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring duplicate volume measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df[['Sample', 'Drug', 'Day', 'Tumor Volume mm3']]))\n",
    "print(len(df[['Sample', 'Drug', 'Day', 'Tumor Volume mm3']].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ['Sample', 'Drug', 'Day', 'Tumor Volume mm3']\n",
    "g = df.groupby(c)['Replicate Number'].count().reset_index(name='nreplicates')\n",
    "grep = g.loc[g['nreplicates'] > 1]\n",
    "grep = grep.sort_values(by='Tumor Volume mm3', ascending=False)\n",
    "grep.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = grep.groupby(['Sample', 'Drug'])['Day'].nunique().reset_index(name='nprs')\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 'HCI-019'\n",
    "drug = 'Birinapant'\n",
    "day = 22\n",
    "vol = 503.3815\n",
    "\n",
    "df.loc[(df['Sample'] == sample) & (df['Drug'] == drug) & (df['Day'] == day) & (df['Tumor Volume mm3'] == vol)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['Sample'] == 'HCI-011') & (df['Drug'] == 'Vehicle') & (df['Day'] == 15) & (df['Tumor Volume mm3'] == 550.525)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we know that there are no duplicates left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Sample', 'Drug', 'Replicate Number', 'excel_sheet']\n",
    "assert df.groupby(cols)['Tumor Volume mm3'].nunique().max() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.loc[g['sheet_ct'] > 1].Sample.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.excel_sheet.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I really only want to keep the 5 drugs that overlap between the two datasets: \n",
    "# 'Navitoclax', 'Birinapant', 'Docetaxel', 'RO4929097', 'Fulvestrant', 'Vehicle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['source_file'] == '43018_2022_337_MOESM10_ESM.xlsx'].Drug.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.excel_sheet.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by (Sample, Drug, Replicate Number)  does not uniquely identify a mouse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select for Sample: HCI-015, Drug: Vehicle, Replicate Number: M0. Note that (1) the measurements for excel_sheet \"6d mid\" and \"6f top right\" are duplicates and (2) the measurements from \"7d left\" are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df.loc[(df['Sample'] == 'HCI-015') & (df['Drug'] == 'Vehicle') & (df['Replicate Number'] == 'M0')]\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data that's hard to identify as duplicated\n",
    "From looking through the excel sheets, I also found that sheet '3f left' and '3h left' have some data that is duplicated, but which is hard to identify as duplicated because the drugs are named differently. The duplication makes sense for the context: '3h left' is a long (100+ day) experiment and '3f left' shows the data for the first weeks of the experiment. However in '3h left' the drug is labeled as 'Fulvestrant' and in '3f left' the drug is labeled as 'Fulvestrant (200 mg/kg)'. For example, in the following two dataframes, the volume measurements are the same through day 26.\n",
    "\n",
    "I think my main question here is how to check for other data that is duplicated, but which doesn't match exactly on one of the main values like Sample, Drug, or Replicate Number. I'm not sure if there is other duplicated data like this, but it seems like it would be good to check for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex1 = df.loc[(df['Sample'] == 'HCI-003') & (df['Replicate Number'] == 'M0') & (df['excel_sheet'] == '3f left') & (df['Drug'] == 'Fulvestrant (200 mg/kg)')]\n",
    "ex1.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = df.loc[(df['Sample'] == 'HCI-003') & (df['Replicate Number'] == 'M0') & (df['excel_sheet'] == '3h left') & (df['Drug'] == 'Fulvestrant')]\n",
    "ex2.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: An attempt at assigning unique identifiers to mice (work in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's look at each ('Sample', 'Drug', 'Replicate Number', 'Day', 'excel_sheet') tuple and count the number of associated unique volume measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Sample', 'Drug', 'Replicate Number', 'Day', 'excel_sheet'])['Tumor Volume mm3'].nunique().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tuples have multiple volume measurements, even in the same excel sheet. This is because the Extended Data Figure (ED1) includes some mice who were given multiple tumors. For now, let's remove the ED1 sheets, to make things simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove data corresponding to ED1 sheets\n",
    "ed_sheets = ['ED1c', 'ED1d left', 'ED1d right', 'ED1e left', 'ED1e right', 'ED1f left', 'ED1f right', \n",
    "             'ED1g left', 'ED1g right']\n",
    "d = df.loc[~df.excel_sheet.isin(ed_sheets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.groupby(['Sample', 'Drug', 'Replicate Number', 'Day', 'excel_sheet'])['Tumor Volume mm3'].nunique().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we see that each ('Sample', 'Drug', 'Replicate Number', 'Day', 'excel_sheet') tuple now has exactly 1 volume measurement. To start, we'll assign an ID to each ('Sample', 'Drug', 'Replicate Number', 'excel_sheet') tuple. Some sheets have duplicate data, so this will likely be overcounting mice, but we can collapse duplicated data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign an MID to each (Sample, Drug, Replicate Number, excel_sheet) tuple\n",
    "t1 = ['Sample', 'Drug', 'Replicate Number', 'excel_sheet']\n",
    "old_len = len(d)\n",
    "d = d.merge(d.groupby(t1).apply(lambda x: x.name).reset_index(name='ID'), \n",
    "              on=t1, \n",
    "              validate='many_to_one')\n",
    "assert len(d) == old_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique IDs: ' + str(d.ID.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described before, it seems likely that multiple IDs correspond to the same mouse. So we need a way to collapse these IDs. Here I am going to assume that if two ('Sample', 'Drug', 'Replicate Number', 'Day', 'Tumor Volume mm3') tuples are identical, they correspond to the same mouse. Next we'll groupby said tuple and examine the associated IDs. We assume that all the IDs associated with a unique tuple correspond to the same mouse, and should be collapsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = ['Sample', 'Drug', 'Replicate Number', 'Day', 'Tumor Volume mm3']\n",
    "g = d.groupby(t2).ID.aggregate(lambda x: x.unique().tolist()).reset_index(name='id_list')\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look up the example tuple from Part 1 ('HCI-015', 'Vehicle', 'M0') in dataframe g. Note that the duplicated measurements from Part 1 are now collapsed. The cases where we had multiple measurements on the same day can be separated out by their different file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.loc[(g['Sample'] == 'HCI-015') & (g['Drug'] == 'Vehicle') & (g['Replicate Number'] == 'M0')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'd like to map each ID to an MID so that if two IDs appear in the same id_list, they are mapped to the same MID. This should result in a one-to-one mapping between mice and MIDs. (I haven't finished this yet...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of unique id_list's\n",
    "unique_lists = []\n",
    "for elem in list(g.id_list):\n",
    "    append = True\n",
    "    for s in unique_lists:\n",
    "        if elem == s:\n",
    "            append = False\n",
    "    if append:\n",
    "        unique_lists.append(elem)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there any id's that appear in multiple lists?\n",
    "id_counts = {}\n",
    "for id_name in list(d.ID):\n",
    "    count = 0\n",
    "    for l in unique_lists:\n",
    "        for elt in l:\n",
    "            if id_name == elt:\n",
    "                count += 1\n",
    "    id_counts[id_name] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_name in id_counts.keys():\n",
    "    if id_counts[id_name] > 1:\n",
    "        print(id_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "My next goal is to create sets of IDs that all belong together (because they appear in id_lists together) and assign each set an MID. Then I would map each ID in the set to it's respective MID. These MIDs will (hopefully) uniquely identify mice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
